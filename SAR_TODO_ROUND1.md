# ðŸ SAR Narrative Generator â€” Round 1 TODO

> **Goal:** Submit Abstract + Semi-Working Prototype with Screenshots  
> **Deadline:** Feb 17, 2026 â€” 11:59 PM IST  
> **Team:** 5 Members | **Legend:** `[ ]` Todo Â· `[/]` In Progress Â· `[x]` Done

---

## ðŸ“‚ File Ownership Map (Zero Conflict Guarantee)

Each person works in **completely separate directories/files**. No two people touch the same file.

```
Hack-O-Hire/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                â† P1 ONLY
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes.py          â† P1 ONLY
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py         â† P1 ONLY
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_pipeline.py    â† P2 ONLY
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_engine.py      â† P2 ONLY
â”‚   â”‚   â”‚   â””â”€â”€ audit_logger.py    â† P2 ONLY
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ data_parser.py     â† P4 ONLY
â”‚   â”œâ”€â”€ knowledge_base/            â† P2 ONLY
â”‚   â””â”€â”€ requirements.txt           â† P1 ONLY (others tell P1 what to add)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py                     â† P3 ONLY
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”œâ”€â”€ dashboard.py           â† P3 ONLY
â”‚   â”‚   â”œâ”€â”€ sar_editor.py          â† P3 ONLY
â”‚   â”‚   â””â”€â”€ audit_trail.py         â† P3 ONLY
â”‚   â””â”€â”€ components/                â† P3 ONLY
â”œâ”€â”€ ml_models/
â”‚   â””â”€â”€ typology_classifier.py     â† P4 ONLY
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data/               â† P4 ONLY
â”œâ”€â”€ screenshots/                   â† P5 ONLY
â”œâ”€â”€ TeamName_CampusName_160226.md  â† P5 ONLY
â”œâ”€â”€ SAR_PPT_DATA.md                â† P5 ONLY
â”œâ”€â”€ docker-compose.yml             â† P1 ONLY
â””â”€â”€ README.md                      â† P5 ONLY
```

---

## Phase 1: Setup & Skeleton (First 2 Hours â€” All Parallel)

> Everyone sets up their environment + creates their file skeletons.  
> **Sync Point:** Quick 5-min call after Phase 1 to confirm all skeletons are in place.

### P1 â€” Backend Lead
- [ ] Create project folder structure (`backend/app/`, `api/`, `core/`, `utils/`)
- [ ] Set up Python venv, create `requirements.txt` with: `fastapi`, `uvicorn`, `sqlalchemy`, `pydantic`, `python-multipart`
- [ ] Create `docker-compose.yml` with PostgreSQL service
- [ ] Create `main.py` â€” FastAPI app with CORS, basic health check endpoint
- [ ] Create `schemas.py` â€” Pydantic models for: `TransactionAlert`, `CustomerKYC`, `SARNarrative`, `AuditEntry`
- [ ] Create stub `routes.py` with endpoint signatures (return dummy data for now):
  - `POST /api/upload` â€” accept CSV/JSON upload
  - `POST /api/generate-sar` â€” trigger SAR generation
  - `GET /api/sar/{id}` â€” get SAR + audit trail
  - `PUT /api/sar/{id}` â€” update SAR
  - `POST /api/sar/{id}/approve` â€” approve SAR

### P2 â€” LLM/RAG Engineer
- [ ] Install Ollama, pull `llama3.1:8b` model
- [ ] Create `llm_engine.py` â€” wrapper class to call Ollama with system prompt
- [ ] Create `rag_pipeline.py` â€” skeleton with ChromaDB setup + LangChain retrieval chain
- [ ] Create `audit_logger.py` â€” LangChain callback handler that captures: input â†’ prompt â†’ context â†’ output â†’ reasoning
- [ ] Create `knowledge_base/` folder with:
  - [ ] `sar_templates/` â€” 3 sample SAR narrative templates (structuring, smurfing, layering)
  - [ ] `regulations/` â€” Copy-paste key FinCEN guidelines into text files
- [ ] Test: Ollama responds to a basic prompt

### P3 â€” Frontend Lead
- [ ] Create `frontend/app.py` â€” Streamlit multipage app skeleton
- [ ] Create `pages/dashboard.py` â€” layout with sidebar nav, placeholder cards
- [ ] Create `pages/sar_editor.py` â€” split-screen layout (data left, editor right)
- [ ] Create `pages/audit_trail.py` â€” expandable timeline layout
- [ ] Set up Streamlit theming (dark mode, custom colors)
- [ ] Add placeholder/mock data so each page renders something visual

### P4 â€” Data & ML Engineer
- [ ] Download SAML-D dataset from Kaggle (or a subset ~50K rows)
- [ ] Download IBM AMLSim sample from Kaggle
- [ ] Create `data/sample_data/` with 3 curated demo scenarios:
  - `scenario_smurfing.csv` â€” 47 senders, 1 receiver, â‚¹50L total
  - `scenario_layering.csv` â€” shell company round-tripping
  - `scenario_structuring.csv` â€” sub-threshold deposits
- [ ] Create `data_parser.py` â€” reads CSV/JSON, returns normalized `TransactionAlert` objects
- [ ] Create `typology_classifier.py` â€” skeleton: load data, feature engineering stubs
- [ ] Begin training XGBoost on SAML-D (can run overnight if needed)

### P5 â€” Docs & Submission Lead
- [ ] Finalize `TeamName_CampusName_160226.md` â€” replace placeholders (team name, campus, member names)
- [ ] Review & polish Abstract (keep 100-200 words)
- [ ] Set up `screenshots/` folder
- [ ] Start preparing PPT structure (from `SAR_PPT_DATA.md`)
- [ ] Create `README.md` with project overview + setup instructions
- [ ] Research competitor SAR tools for "why we're better" slide

---

## Phase 2: Core Working Prototype (Next 4 Hours â€” All Parallel)

> Each person builds their working component independently.  
> **Contract:** Everyone exposes/consumes data via **JSON dict** format â€” no cross-imports.  
> **Sync Point:** Quick call after Phase 2 to test connections.

### P1 â€” Backend: Wire Up Real API
- [ ] Implement `POST /api/upload` â€” parse uploaded CSV, store in PostgreSQL (or in-memory dict for prototype)
- [ ] Implement `POST /api/generate-sar` â€” call P2's `llm_engine` module, return result
- [ ] Implement `GET /api/sar/{id}` â€” return stored SAR + audit trail
- [ ] Implement `PUT /api/sar/{id}` â€” accept edited narrative, track diff
- [ ] Implement `POST /api/sar/{id}/approve` â€” change status to approved
- [ ] Add simple in-memory storage (dict) as DB fallback if PostgreSQL isn't ready
- [ ] Test all endpoints with `curl` or Postman

### P2 â€” LLM/RAG: Working Narrative Generation
- [ ] Build full system prompt for SAR generation:
  - Instruct FinCEN format (Introduction â†’ Body â†’ Conclusion)
  - Include 5Ws + How structure
  - Add unbiased/on-topic guardrails
- [ ] Index knowledge base documents into ChromaDB
- [ ] Build RAG chain: query â†’ retrieve templates â†’ augment prompt â†’ generate
- [ ] Implement audit logger callback: capture full trace per generation
- [ ] Create a `generate_sar(alert_data: dict) -> dict` function that returns:
  ```python
  {
    "narrative": "...",      # The SAR text
    "audit_trail": [...],    # List of reasoning steps
    "quality_score": 0.85,   # Basic completeness check
    "typology": "structuring" # Detected pattern
  }
  ```
- [ ] Test: Feed scenario_smurfing.csv â†’ get a real SAR narrative out

### P3 â€” Frontend: Working UI Pages
- [ ] **Dashboard:** Show list of uploaded cases with status badges (Draft/Review/Approved)
- [ ] **Upload page:** File uploader â†’ show parsed data in table
- [ ] **SAR Editor:**
  - Left panel: show transaction data summary + risk highlights
  - Right panel: editable text area with generated narrative
  - Buttons: Regenerate, Approve, Export
- [ ] **Audit Trail page:**
  - Expandable cards showing each reasoning step
  - Color-coded: data points (blue), rules (orange), rationale (green)
- [ ] Wire up to backend API (use `requests` to call FastAPI endpoints)
- [ ] If backend not ready, use **mock JSON responses** so UI is fully demo-able

### P4 â€” ML: Working Classifier + Data Pipeline
- [ ] Complete XGBoost training on SAML-D dataset features:
  - Transaction amount, frequency, num counterparties, time gaps, amount variance
- [ ] Save trained model as `.joblib` file
- [ ] Create `predict_typology(transactions: list) -> dict` function:
  ```python
  {
    "typology": "structuring",
    "confidence": 0.92,
    "features_importance": {"amount": 0.35, "frequency": 0.28, ...}
  }
  ```
- [ ] Create SHAP explanation for top features
- [ ] Wire `data_parser.py` to produce clean input for both P1's API and P2's LLM engine
- [ ] Generate risk scores for demo scenarios

### P5 â€” Screenshots & Submission Polish
- [ ] Take screenshots of P3's UI (even with mock data â€” it's fine)
- [ ] Take screenshot of P2's generated SAR narrative (terminal output is fine)
- [ ] Take screenshot of audit trail output
- [ ] Add screenshots to submission document under architecture/methodology sections
- [ ] Polish submission doc: add performance claims, accuracy numbers from P4's classifier
- [ ] Start building PPT slides (Google Slides / PowerPoint)

---

## Phase 3: Integration & Demo-Ready (Final 3 Hours)

> **This is the ONLY phase where people touch shared integration points.**  
> P1 leads integration; others provide their modules.

### P1 â€” Integration Captain
- [ ] Integrate P2's `generate_sar()` function into `POST /api/generate-sar` route
- [ ] Integrate P4's `predict_typology()` into the generation pipeline
- [ ] Ensure audit trail flows from P2 â†’ PostgreSQL â†’ API â†’ Frontend
- [ ] Test full end-to-end: Upload CSV â†’ Generate SAR â†’ View Audit â†’ Edit â†’ Approve
- [ ] Fix any bugs in API contracts

### P2 â€” LLM Quality Tuning
- [ ] Improve prompt based on initial outputs (make narrative more professional)
- [ ] Add quality scoring logic (completeness check: are all 5Ws present?)
- [ ] Test with all 3 demo scenarios â€” ensure each produces good output
- [ ] Fine-tune audit trail formatting for clean display

### P3 â€” Frontend Polish + Screenshots
- [ ] Connect to live backend (replace mocks with real API calls)
- [ ] Add loading spinners during SAR generation
- [ ] Polish dark mode styling
- [ ] Take **final screenshots** of working prototype for submission
- [ ] Record screen GIF/video if time permits

### P4 â€” Final Model + Demo Data
- [ ] Verify classifier accuracy on test set (aim for >80%)
- [ ] Generate prediction results for all 3 demo scenarios
- [ ] Create summary stats for submission doc (accuracy, F1, precision)
- [ ] Ensure data_parser handles edge cases in demo CSVs

### P5 â€” Final Submission Assembly
- [ ] Update submission doc with final screenshots
- [ ] Add classifier accuracy metrics to methodology section
- [ ] Add SAR narrative sample output to the document
- [ ] Final proofread of Abstract (100-200 words, crisp)
- [ ] Convert markdown â†’ `.doc` format
- [ ] Build final PPT (from `SAR_PPT_DATA.md`)
- [ ] Rename files: `TeamName_CampusName_170226.doc` / `.ppt`
- [ ] Verify total size < 45 MB
- [ ] **SUBMIT** ðŸŽ‰

---

## â° Timeline (Clock-based for Feb 16â€“17)

| Time | Phase | Status |
|------|-------|--------|
| **8:00 PM â€“ 10:00 PM** (Feb 16) | Phase 1: Setup & Skeleton | All parallel |
| 10:00 PM | âš¡ **Sync call** (5 min) | Confirm skeletons work |
| **10:00 PM â€“ 2:00 AM** (Feb 16â€“17) | Phase 2: Core Prototype | All parallel |
| 2:00 AM | âš¡ **Sync call** (10 min) | Test API connections |
| **2:00 AM â€“ 5:00 AM** (Feb 17) | Phase 3: Integration & Polish | P1 leads integration |
| **5:00 AM â€“ 8:00 AM** | Sleep / Break ðŸ’¤ | |
| **8:00 AM â€“ 12:00 PM** | Final polish + Submission prep | P5 leads |
| **12:00 PM â€“ 11:59 PM** | Buffer + Submit | |

---

## ðŸ¤ Integration Contracts (How Modules Connect)

> These are the **agreed JSON shapes** that each person's code must produce/consume.  
> As long as everyone follows these, code will plug together with zero conflicts.

### Contract 1: P4 â†’ P1 (Data Parser â†’ API)
```json
// P4's data_parser.parse_csv(file) returns:
{
  "case_id": "CASE-001",
  "transactions": [
    {
      "txn_id": "TXN-001",
      "sender": "Account-A",
      "receiver": "Account-B",
      "amount": 500000,
      "currency": "INR",
      "timestamp": "2026-01-15T10:30:00",
      "type": "NEFT"
    }
  ],
  "customer": {
    "name": "Rajesh Kumar",
    "account_id": "XXXX-4521",
    "kyc_status": "verified",
    "business_type": "Textile Export",
    "avg_monthly_volume": 300000
  }
}
```

### Contract 2: P1 â†’ P2 (API â†’ LLM Engine)
```json
// P1 calls: P2.generate_sar(case_data)
// Input: the parsed case data from Contract 1
// Output:
{
  "sar_id": "SAR-001",
  "narrative": {
    "introduction": "This SAR is being filed to report...",
    "body": "WHO: ... WHAT: ... WHEN: ... WHERE: ... WHY: ... HOW: ...",
    "conclusion": "Based on the above analysis..."
  },
  "audit_trail": [
    {
      "step": 1,
      "agent": "data_analyst",
      "action": "Analyzed 47 inbound transactions",
      "data_points_used": ["47 senders", "â‚¹50L total", "7-day window"],
      "output": "High-risk pattern: multiple small transfers consolidated"
    },
    {
      "step": 2,
      "agent": "compliance_mapper",
      "action": "Matched to FinCEN typology",
      "rules_matched": ["Structuring", "Smurfing"],
      "output": "Primary typology: Structuring (confidence: 92%)"
    }
  ],
  "quality_score": {
    "completeness": 0.95,
    "compliance": 0.98,
    "readability": 0.88,
    "evidence_linkage": 0.91
  },
  "typology": {
    "prediction": "structuring",
    "confidence": 0.92
  },
  "status": "draft"
}
```

### Contract 3: P1 â†’ P3 (API â†’ Frontend)
```json
// P3 calls GET /api/sar/{id} and receives the same structure as Contract 2
// P3 calls GET /api/cases and receives:
{
  "cases": [
    {
      "case_id": "CASE-001",
      "customer_name": "Rajesh Kumar",
      "alert_type": "High Volume Inbound",
      "risk_level": "HIGH",
      "sar_status": "draft",
      "created_at": "2026-02-17T10:30:00"
    }
  ]
}
```

### Contract 4: P4 â†’ P2 (ML Model â†’ LLM Engine)
```json
// P2 calls: P4.predict_typology(transactions)
// Output:
{
  "typology": "structuring",
  "confidence": 0.92,
  "top_features": {
    "num_unique_senders": 0.35,
    "total_amount": 0.28,
    "time_window_days": 0.22,
    "amount_variance": 0.15
  }
}
```

---

## ðŸŽ¯ Round 1 Submission Checklist

- [ ] Abstract document (100-200 words) âœ“
- [ ] System Architecture diagram with component descriptions âœ“
- [ ] Methodology section (scalability, performance, security) âœ“
- [ ] Tech stack listing âœ“
- [ ] Future scope âœ“
- [ ] Screenshots of working prototype (minimum 3):
  - [ ] Dashboard / upload screen
  - [ ] Generated SAR narrative
  - [ ] Audit trail view
- [ ] Semi-working prototype running locally
- [ ] ML model trained with accuracy metrics
- [ ] File named: `TeamName_CampusName_170226.doc`
- [ ] PPT named: `TeamName_CampusName_170226.ppt`
- [ ] Total size < 45 MB
